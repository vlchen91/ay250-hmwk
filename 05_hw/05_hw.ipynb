{
 "metadata": {
  "name": "05_hw"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Run ipython with --pylab\n",
      "\n",
      "from matplotlib import image as mpimg\n",
      "import os\n",
      "import string\n",
      "import cPickle\n",
      "\n",
      "from scipy.ndimage.filters import correlate1d\n",
      "import skimage\n",
      "from skimage.filter import sobel, canny\n",
      "from skimage.feature import greycomatrix, greycoprops\n",
      "\n",
      "from scipy import ndimage\n",
      "from scipy.ndimage import watershed_ift\n",
      "#from skimage import img_as_ubyte\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2) Write a set of methods that takes as input one of these images, and then computes real-numbered features as the return."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n",
      "Number   Feature                Number   Feature                Number   Feature                Number   Feature\n",
      "------   ------------------     ------   ------------------     ------   ------------------     ------   --------------------------     \n",
      "1        number of pixels       6        Corner GLCM x-var      11       Center GLCM y-mean     16       Density of edges 4\n",
      "2        avg R intensity        7        Corner GLCM y-mean     12       Center GLCM y-var      17       Segmentation Label Count 1\n",
      "3        avg G intensity        8        Corner GLCM y-var      13       Density of edges 1     18       Segmentation Label Count 2\n",
      "4        avg B intensity        9        Center GLCM x-mean     14       Density of edges 2     19       Segmentation Label Count 3\n",
      "5        Corner GLCM x-mean     10       Center GLCM x-var      15       Density of edges 3\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "img_classes = dict()\n",
      "for dirname, dirnames, filenames in os.walk('50_categories/'):\n",
      "    for ind,img_class in enumerate(dirnames):\n",
      "        img_classes[img_class] = ind\n",
      "\n",
      "data = []\n",
      "target = []\n",
      "\n",
      "for dirname, dirnames, filenames in os.walk('50_categories/'):\n",
      "    for filename in filenames:\n",
      "        if not filename[-4:] == '.jpg':\n",
      "            continue\n",
      "        fullfilename = os.path.join(dirname, filename)\n",
      "        img = mpimg.imread(fullfilename,'rb')\n",
      "        ## The following bug is not fixed yet: imread flips the image upside-down\n",
      "        img = np.flipud(img)\n",
      "        if len(img.shape) == 2:\n",
      "            img = np.dstack( (img, img, img) )\n",
      "            \n",
      "            \n",
      "        pos = string.find(filename,'_')\n",
      "        cat = filename[:pos]\n",
      "        target.append(img_classes[cat])\n",
      "        \n",
      "        features = []\n",
      "        ######## Compute 15 features ########\n",
      "        \n",
      "        ###### No. 1: image size, or number of pixels ------------------------------------\n",
      "        num_pixels = img[...,0].size\n",
      "        features.append(num_pixels)\n",
      "        \n",
      "        ###### No. 2-4: avg of the RGB channel intensity ---------------------------------\n",
      "        avg_R = np.mean(img[...,0])\n",
      "        features.append(avg_R)\n",
      "        avg_G = np.mean(img[...,1])\n",
      "        features.append(avg_G)\n",
      "        avg_B = np.mean(img[...,2])\n",
      "        features.append(avg_B)\n",
      "        \n",
      "        ###### No. 5-8: GLCM for corner patches ------------------------------------------\n",
      "        # RGB --> gray\n",
      "        try:\n",
      "            r,g,b = np.rollaxis(img,axis=-1)\n",
      "        except:\n",
      "            print fullfilename\n",
      "        gray = (0.299*r + 0.587*g + 0.114*b).astype('int');\n",
      "        \n",
      "        PATCH_SIZE = 20\n",
      "        # select some corner patches\n",
      "        TL = (0,0)\n",
      "        TR = (0,gray.shape[1] - 1 - PATCH_SIZE)\n",
      "        BL = (gray.shape[0] - 1 - PATCH_SIZE, 0)\n",
      "        BR = (gray.shape[0] - 1 - PATCH_SIZE, gray.shape[1] - 1 - PATCH_SIZE)\n",
      "        locs = [TL, TR, BL, BR]\n",
      "        corner_patches = []\n",
      "        for loc in locs:\n",
      "            corner_patches.append(gray[loc[0]:loc[0] + PATCH_SIZE,\n",
      "                                       loc[1]:loc[1] + PATCH_SIZE])\n",
      "        # compute some GLCM properties each patch\n",
      "        xs = []\n",
      "        ys = []\n",
      "        for i, patch in enumerate(corner_patches):\n",
      "            glcm = greycomatrix(patch, [5], [0], 256, symmetric=True, normed=True)\n",
      "            xs.append(greycoprops(glcm, 'dissimilarity')[0, 0])\n",
      "            ys.append(greycoprops(glcm, 'correlation')[0, 0])\n",
      "        \n",
      "        features.append(np.mean(xs))\n",
      "        features.append(np.var(xs))\n",
      "        features.append(np.mean(ys))\n",
      "        features.append(np.var(ys))\n",
      "        \n",
      "        ###### No. 9-12: GLCM for central patches ----------------------------------------\n",
      "        # RGB --> gray\n",
      "        #r,g,b = np.rollaxis(img,axis=-1)\n",
      "        gray = (0.299*r + 0.587*g + 0.114*b).astype('int');\n",
      "        \n",
      "        PATCH_SIZE = 20\n",
      "        # select some center patches\n",
      "        center = (gray.shape[0] / 2, gray.shape[1] / 2)\n",
      "        TL = (center[0] - PATCH_SIZE, center[1] - PATCH_SIZE)\n",
      "        TR = (center[0] - PATCH_SIZE, center[1] + PATCH_SIZE)\n",
      "        BL = (center[0] + PATCH_SIZE, center[1] - PATCH_SIZE)\n",
      "        BR = (center[0] + PATCH_SIZE, center[1] + PATCH_SIZE)\n",
      "        locs = [TL, TR, BL, BR]\n",
      "        corner_patches = []\n",
      "        for loc in locs:\n",
      "            corner_patches.append(gray[loc[0]:loc[0] + PATCH_SIZE,\n",
      "                                       loc[1]:loc[1] + PATCH_SIZE])\n",
      "        # compute some GLCM properties each patch\n",
      "        xs = []\n",
      "        ys = []\n",
      "        for i, patch in enumerate(corner_patches):\n",
      "            glcm = greycomatrix(patch, [5], [0], 256, symmetric=True, normed=True)\n",
      "            xs.append(greycoprops(glcm, 'dissimilarity')[0, 0])\n",
      "            ys.append(greycoprops(glcm, 'correlation')[0, 0])\n",
      "        \n",
      "        features.append(np.mean(xs))\n",
      "        features.append(np.var(xs))\n",
      "        features.append(np.mean(ys))\n",
      "        features.append(np.var(ys))\n",
      "        \n",
      "        ###### No. 13-16: Edges (Sobel & Canny) ------------------------------------------\n",
      "        # Proportion of image that are edges\n",
      "        \n",
      "        # sobel works only with float32, not uint8\n",
      "        #\n",
      "        gray = 0.299*r + 0.587*g + 0.114*b;\n",
      "        edges_sobel = sobel(gray)\n",
      "        SOBEL_THRESHOLD_1 = np.max(edges_sobel.flat) / 10\n",
      "        edges_sobel_size = edges_sobel[edges_sobel > SOBEL_THRESHOLD_1].size\n",
      "        edges_sobel_ratio_1 = edges_sobel_size * 1. / gray.size\n",
      "        SOBEL_THRESHOLD_2 = np.max(edges_sobel.flat) / 5\n",
      "        edges_sobel_size = edges_sobel[edges_sobel > SOBEL_THRESHOLD_2].size\n",
      "        edges_sobel_ratio_2 = edges_sobel_size * 1. / gray.size\n",
      "        SOBEL_THRESHOLD_3 = np.max(edges_sobel.flat) / 3\n",
      "        edges_sobel_size = edges_sobel[edges_sobel > SOBEL_THRESHOLD_3].size\n",
      "        edges_sobel_ratio_3 = edges_sobel_size * 1. / gray.size\n",
      "\n",
      "        edges_canny = canny(gray).astype('int');\n",
      "        edges_canny_ratio = np.sum(edges_canny.astype(int)) * 1. / gray.size;\n",
      "        \n",
      "        features.append(edges_sobel_ratio_1)\n",
      "        features.append(edges_sobel_ratio_2)\n",
      "        features.append(edges_sobel_ratio_3)\n",
      "        features.append(edges_canny_ratio)\n",
      "        \n",
      "        ###### No. 17-19: Segmentation (label count) -------------------------------------\n",
      "        gray = (0.299*r + 0.587*g + 0.114*b).astype('int');\n",
      "        elevation_map = sobel(gray)\n",
      "        elevation_map = elevation_map / np.max(elevation_map)\n",
      "        elevation_map = (elevation_map * 255).astype('uint8')\n",
      "        \n",
      "        markers = np.zeros_like(gray);\n",
      "        markers[gray < 30] = 1\n",
      "        markers[gray > 150] = 2\n",
      "        segmentation = watershed_ift(elevation_map,markers)\n",
      "        segmentation = ndimage.binary_fill_holes(segmentation - 1)\n",
      "        labeled_elements, count = ndimage.label(segmentation)\n",
      "        features.append(count)\n",
      "        \n",
      "        markers = np.zeros_like(gray)\n",
      "        markers[gray < 80] = 1\n",
      "        markers[gray > 180] = 2\n",
      "        segmentation = watershed_ift(elevation_map,markers)\n",
      "        segmentation = ndimage.binary_fill_holes(segmentation - 1)\n",
      "        labeled_elements, count = ndimage.label(segmentation)\n",
      "        features.append(count)\n",
      "        \n",
      "        markers = np.zeros_like(gray)\n",
      "        markers[gray < 100] = 1\n",
      "        markers[gray > 200] = 2\n",
      "        segmentation = watershed_ift(elevation_map,markers)\n",
      "        segmentation = ndimage.binary_fill_holes(segmentation - 1)\n",
      "        labeled_elements, count = ndimage.label(segmentation)\n",
      "        features.append(count)\n",
      "         \n",
      "        ###### Store features into data --------------------------------------------------\n",
      "        data.append(features)\n",
      "\n",
      "#Dump into pickle to save computation time\n",
      "f = open('data_pickled.dat','wb')\n",
      "p = cPickle.Pickler(f)\n",
      "data = np.array(data,dtype='float16')\n",
      "p.dump(data)\n",
      "f.close()\n",
      "\n",
      "f = open('target_pickled.dat','wb')\n",
      "p = cPickle.Pickler(f)\n",
      "target = np.array(target)\n",
      "p.dump(target)\n",
      "f.close()\n",
      "\n",
      "f = open('img_classes_pickled.dat','wb')\n",
      "p = cPickle.Pickler(f)\n",
      "p.dump(img_classes)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Restore session from data_pickled.dat and target_pickled.dat\n",
      "f = open('data_pickled.dat','rb')\n",
      "p = cPickle.Unpickler(f)\n",
      "data = p.load()\n",
      "f.close()\n",
      "\n",
      "f = open('target_pickled.dat', 'rb')\n",
      "p = cPickle.Unpickler(f)\n",
      "target = p.load()\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3) Based on the feature set for each image, build a random forest classifier (scikits.learn). Produce metrics on your estimated error rates using cross-validation. How much better is this than the expectation with random guessing? What are the 3 most important features?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "My classifier has a 27.33% success rate, which is around 14 times more accurate random guessing. Not great, but at least better."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Construct a random forest classifier\n",
      "parameters = {'n_estimators':[20,60,100], 'max_features':[3,11,19], \\\n",
      "              'compute_importances':[True]}\n",
      "rf_tune = GridSearchCV(RandomForestClassifier(), \\\n",
      "            parameters, score_func=metrics.zero_one_score, n_jobs=-1, cv=5)\n",
      "\n",
      "rf_opt = rf_tune.fit(data,target)\n",
      "\n",
      "print \"Best zero-one score: \" + str(rf_opt.best_score_) + '\\n'\n",
      "print \"Optimal Model:\\n\" + str(rf_opt.best_estimator_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best zero-one score: 0.273327110696\n",
        "\n",
        "Optimal Model:\n",
        "RandomForestClassifier(bootstrap=True, compute_importances=True,\n",
        "            criterion=gini, max_depth=None, max_features=3,\n",
        "            min_density=0.1, min_samples_leaf=1, min_samples_split=1,\n",
        "            n_estimators=100, n_jobs=1, oob_score=False,\n",
        "            random_state=<mtrand.RandomState object at 0x24e840>,\n",
        "            verbose=0)\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "\n",
      "The 3 most important features are:\n",
      "1. feature 10: Center GLCM variance in the x direction\n",
      "2. feature 3: Average green intensity\n",
      "3. feature 14: Density of edges, using the sobel filter\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "importances = rf_opt.best_estimator_.feature_importances_\n",
      "indices = np.argsort(importances)[::-1]\n",
      "\n",
      "# Print the feature ranking\n",
      "print \"Feature ranking:\"\n",
      "\n",
      "for f in xrange(10):\n",
      "    print \"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]])\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature ranking:\n",
        "1. feature 10 (0.083189)\n",
        "2. feature 3 (0.059530)\n",
        "3. feature 14 (0.058079)\n",
        "4. feature 2 (0.057128)\n",
        "5. feature 8 (0.057123)\n",
        "6. feature 1 (0.057043)\n",
        "7. feature 15 (0.056505)\n",
        "8. feature 12 (0.054757)\n",
        "9. feature 13 (0.053443)\n",
        "10. feature 4 (0.052120)\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pickle the classifier for future use\n",
      "f = open('clf_pickled.dat','wb')\n",
      "p = cPickle.Pickler(f)\n",
      "p.dump(rf_opt.best_estimator_)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Part 4)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "4) Make sure your final classifier can run on a directory of different images, where a call like:\n",
      "run_final_classifier(\"/new/directory/path/\")\n",
      "on directory that contains files like:\n",
      "validation1.jpg\n",
      "validation2.jpg\n",
      "...\n",
      "will produce an output file that looks like:\n",
      "filename         predicted_class\n",
      "------------------------------------\n",
      "validation1.jpg  unicorn\n",
      "validation2.jpg  camel\n",
      "...\n",
      "We will have a validation set to test how good your classifier is. The best classifier among those submitted will earn its writer a perfect score on this homework."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# See run_final_classifier.py\n",
      "import run_final_classifier\n",
      "run_final_classifier.run_final_classifier('test_directory')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "'module' object is not callable",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-63-0b263a2c9676>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_final_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_final_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_directory'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}